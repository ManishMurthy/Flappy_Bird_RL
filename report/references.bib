@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={Nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  journal={MIT press},
  year={2018}
}

@article{schulman2023proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:2005.12729},
  year={2023}
}

@article{badia2020agent57,
  title={Agent57: Outperforming the Atari Human Benchmark},
  author={Badia, Adrià Puigdomènech and Piot, Bilal and Kapturowski, Steven and Sprechmann, Pablo and Vitvitskyi, Alex and Guo, Zhaohan Daniel and Blundell, Charles},
  journal={Proceedings of the 37th International Conference on Machine Learning},
  pages={507--517},
  year={2020}
}

@article{kumar2023offline,
  title={Offline reinforcement learning: Fundamental barriers for value function approximation},
  author={Kumar, Aviral and Zhou, Anikait and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={5780--5792},
  year={2023}
}

@inproceedings{dabney2020distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, Rémi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  year={2020}
}

@article{fujimoto2021minimalist,
  title={A minimalist approach to offline reinforcement learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={20132--20145},
  year={2021}
}

@article{yu2022planning,
  title={Planning with diffusion for flexible behavior synthesis},
  author={Yu, Kevin and Kumar, Abhishek and Tompson, James and Levine, Sergey and Hausman, Karol},
  journal={International Conference on Machine Learning},
  pages={25472--25493},
  year={2022}
}

@article{vinyals2019grandmaster,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Michael and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{hafner2023mastering,
  title={Mastering diverse domains through world models},
  author={Hafner, Danijar and Pasukonis, Jurgis and Ba, Jimmy and Lillicrap, Timothy},
  journal={Nature},
  volume={617},
  number={7952},
  pages={288--294},
  year={2023},
  publisher={Nature Publishing Group}
}

@article{yang2023foundation,
  title={Foundation models for decision making: Problems, methods, and opportunities},
  author={Yang, Sherry and Gu, Albert and Koishida, Katsuhito and Levine, Sergey and Finn, Chelsea and Shixiang, Shane Gu},
  journal={arXiv preprint arXiv:2303.04129},
  year={2023}
}

@article{lee2022multi,
  title={Multi-game decision transformers},
  author={Lee, Kuang-Huei and Nachum, Ofir and Yang, Mengjiao and Lee, Lisa and Freeman, Daniel and Xu, Winnie and Guadarrama, Sergio and Fischer, Ian and Levine, Sergey and Finn, Chelsea and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={36525--36541},
  year={2022}
}

@article{wang2022offline,
  title={Offline reinforcement learning with implicit Q-learning},
  author={Wang, Luyu and Zhang, Qi and Kang, Boyuan and Pan, Jiajun and Bakker, Peter J and Zhou, Kaichun and Lee, Hao and Luo, Jiongxiao and Wang, Hao and Guo, Zhiyuan and Guo, Ofir and Lee, Wenzhen and Lu, Chris},
  journal={arXiv preprint arXiv:2110.06169},
  year={2022}
}

@inproceedings{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Michael and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  booktitle={Advances in Neural Information Processing Systems},
  pages={15084--15097},
  year={2021}
}

@article{chen2021transdreamer,
  title={TransDreamer: Reinforcement learning with transformer world models},
  author={Chen, Lili and Huang, Kevin and Schoelkopf, Haym and Alon, Shikhar and Caspi, Itai and Lev, Guy and Dave, Abishek and Singh, Ravid and Karl, Maximilian and Chitta, Kashyap},
  journal={arXiv preprint arXiv:2202.09481},
  year={2022}
}